{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from time import strftime,strptime,gmtime\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# Visualization libraries\n",
    "# Displays plots in output cell\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier,PassiveAggressiveRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_negative (v):\n",
    "    if v >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_downloader(symbol,days=60,days_ago=0):\n",
    "    #date variables\n",
    "    dt = datetime.datetime.now()\n",
    "    UnixTime = int(time.mktime(dt.timetuple()))\n",
    "    #web variables\n",
    "    url = 'https://query1.finance.yahoo.com/v8/finance/chart/'+symbol+'?period1='+str(UnixTime-86400*(days+days_ago))+'&period2='+str(UnixTime-86400*days_ago)+'&interval=1d&indicators=quote%7Csma~50&includePrePost=true&events=div%7Csplit%7Cearn&lang=en-CA&region=CA&corsDomain=ca.finance.yahoo.com'\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.101 Safari/537.36',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "           'Connection': 'keep-alive'}\n",
    "    #html data request\n",
    "    try:\n",
    "        http = urllib3.PoolManager()\n",
    "        request = http.request('GET', url,headers = hdr)\n",
    "        data = json.loads(request.data.decode('utf-8'))\n",
    "        return data\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_downloader (symbol,days = 365,shift_days = 10):\n",
    "    data = html_downloader(symbol,days = days)\n",
    "    try:     \n",
    "        #json unpack\n",
    "        timestamp = data['chart']['result'][0]['timestamp']\n",
    "        timestamp = [datetime.datetime.fromtimestamp(x).strftime('%Y%m%d') for x in timestamp]\n",
    "        quote = data['chart']['result'][0]['indicators']['quote'][0]\n",
    "        sma50 = data['chart']['result'][0]['indicators']['sma'][0]['sma']\n",
    "        stock_df = pd.DataFrame(quote)\n",
    "        #index is symbol and timestamp\n",
    "        stock_df.index = [symbol + str(x) for x in timestamp]\n",
    "\n",
    "        #moving averages\n",
    "        stock_df['sma'] = sma50\n",
    "        stock_df['vol20'] = stock_df['volume'].rolling(window=20).mean()\n",
    "        #predict on yesterday's averages\n",
    "        stock_df['sma'] = stock_df['sma'].shift(1)\n",
    "        stock_df['vol20'] = stock_df['vol20'].shift(1)\n",
    "        stock_df = stock_df.dropna()\n",
    "\n",
    "        #derived columns\n",
    "        stock_df['c_0'] = stock_df['close']/stock_df['sma']\n",
    "        stock_df['h_0'] = stock_df['high']/stock_df['sma']\n",
    "        stock_df['l_0'] = stock_df['low']/stock_df['sma']\n",
    "        stock_df['o_0'] = stock_df['open']/stock_df['sma']\n",
    "        stock_df['v_0'] = stock_df['volume']/stock_df['vol20']\n",
    "        stock_df['r'] = (stock_df['close']-stock_df['open'])/stock_df['open']\n",
    "\n",
    "        #rolling columns\n",
    "        for d in list(range(1,shift_days+1)):\n",
    "            stock_df['c_'+str(d)] = stock_df['c_0'].shift(d)\n",
    "            stock_df['h_'+str(d)] = stock_df['h_0'].shift(d)\n",
    "            stock_df['l_'+str(d)] = stock_df['l_0'].shift(d)\n",
    "            stock_df['o_'+str(d)] = stock_df['o_0'].shift(d)\n",
    "            stock_df['v_'+str(d)] = stock_df['v_0'].shift(d)\n",
    "        stock_df.drop(['close', 'high', 'low', 'open','volume','sma','vol20'], axis=1, inplace=True)\n",
    "        #do not use current day's intraday data\n",
    "        #stock_df = stock_df.drop(stock_df.index[len(stock_df)-1])\n",
    "        #clean data\n",
    "        stock_df = stock_df.dropna()\n",
    "        stock_df = stock_df[~(stock_df == np.inf).any(axis=1)]\n",
    "        if len(stock_df) != 0:\n",
    "            with open('./data_s/'+symbol+'.p','wb') as f:\n",
    "                pk.dump(stock_df,f)\n",
    "                print (stock_df)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_predict (symbol,clf,clfR,shift_days=10,days_ago = 0):\n",
    "    try:\n",
    "        data = html_downloader(symbol,days_ago = days_ago)\n",
    "        #json unpack\n",
    "        timestamp = data['chart']['result'][0]['timestamp']\n",
    "        timestamp = [datetime.datetime.fromtimestamp(x).strftime('%Y%m%d') for x in timestamp]\n",
    "        quote = data['chart']['result'][0]['indicators']['quote'][0]\n",
    "        sma50 = data['chart']['result'][0]['indicators']['sma'][0]['sma']\n",
    "        stock_df = pd.DataFrame(quote)\n",
    "        #index is symbol and timestamp\n",
    "        stock_df.index = [symbol + str(x) for x in timestamp]\n",
    "\n",
    "        #moving averages\n",
    "        stock_df['sma'] = sma50\n",
    "        stock_df['vol20'] = stock_df['volume'].rolling(window=20).mean()\n",
    "        #predict on yesterday's averages\n",
    "        stock_df['sma'] = stock_df['sma'].shift(1)\n",
    "        stock_df['vol20'] = stock_df['vol20'].shift(1)\n",
    "        stock_df = stock_df.dropna()\n",
    "\n",
    "        #derived columns\n",
    "        stock_df['c_0'] = stock_df['close']/stock_df['sma']\n",
    "        stock_df['h_0'] = stock_df['high']/stock_df['sma']\n",
    "        stock_df['l_0'] = stock_df['low']/stock_df['sma']\n",
    "        stock_df['o_0'] = stock_df['open']/stock_df['sma']\n",
    "        stock_df['v_0'] = stock_df['volume']/stock_df['vol20']\n",
    "\n",
    "        #rolling columns\n",
    "        for d in list(range(1,shift_days+1)):\n",
    "            stock_df['c_'+str(d)] = stock_df['c_0'].shift(d)\n",
    "            stock_df['h_'+str(d)] = stock_df['h_0'].shift(d)\n",
    "            stock_df['l_'+str(d)] = stock_df['l_0'].shift(d)\n",
    "            stock_df['o_'+str(d)] = stock_df['o_0'].shift(d)\n",
    "            stock_df['v_'+str(d)] = stock_df['v_0'].shift(d)\n",
    "        stock_df.drop(['close', 'high', 'low', 'open','volume','sma','vol20','c_0'], axis=1, inplace=True)\n",
    "        stock_df['v_0'] = (stock_df['v_1']+stock_df['v_2']+stock_df['v_3']+stock_df['v_4']+stock_df['v_5'])/5\n",
    "        stock_df['h_0'] = (stock_df['h_1']+stock_df['h_2']+stock_df['h_3']+stock_df['h_4']+stock_df['h_5'])/5\n",
    "        stock_df['l_0'] = (stock_df['l_1']+stock_df['l_2']+stock_df['l_3']+stock_df['l_4']+stock_df['l_5'])/5\n",
    "        stock_df = stock_df.dropna()\n",
    "        stock_df = stock_df[~(stock_df == np.inf).any(axis=1)]\n",
    "    except:\n",
    "        pass\n",
    "    #select last row of downloaded matrix for latest day open price and rolling data\n",
    "    return '%s will go %s by %s, prediction date: %s'%(symbol, str(clf.predict(stock_df.iloc[[-1]].values.tolist())),str(clfR.predict(stock_df.iloc[[-1]].values.tolist())),timestamp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of threads:  96\n"
     ]
    }
   ],
   "source": [
    "#download learning data from list of stocks\n",
    "stock_list = ['fas','faz', 'AA', 'ABT', 'ABX', 'ADI', 'ADM', 'AET', 'AMD', 'AMR', 'APC', 'AVP', 'AXP', 'BA', 'BAC', 'BAX', 'BBY', 'BK', 'BMC', 'BMY', 'BNI', 'BP', 'CA', 'CAT', 'CI', 'CL', 'COP', 'CVX', 'DD', 'DE', 'DIS', 'DOW', 'EK', 'EMC', 'EMR', 'FNM', 'FRE', 'FRX', 'GE', 'GLW', 'GPS', 'GSK', 'HAL', 'HD', 'HON', 'HPQ', 'HRB', 'IBM', 'IGT', 'JNJ', 'JPM', 'JWN', 'KO', 'KR', 'LLY', 'LOW', 'LTD', 'LUV', 'MCD', 'MDT', 'MMM', 'MO', 'MOT', 'MRK', 'MRO', 'MU', 'MYL', 'NKE', 'NSM', 'NWS', 'OXY', 'PEP', 'PFE', 'PG', 'RSH', 'SLB', 'SLE', 'SLM', 'STJ', 'SYK', 'SYY', 'TGT', 'TJX', 'TMX', 'TXN', 'UN', 'UNH', 'UTX', 'VOD', 'VZ', 'WAG', 'WFC', 'WMB', 'WMT', 'XOM', 'XRX']\n",
    "#stock_list = ['^GDAXI','^FTSE','^DJI','^FCHI','^N225','^HSI','^AXJO','^GSPC','^IXIC','^TNX','^VIX']\n",
    "#with open(\"symbols_A.txt\") as symbol_file:\n",
    "    #stock_list = symbol_file.read().split('\\n')\n",
    "threadlist = []\n",
    "for s in stock_list:\n",
    "    t = threading.Thread(target = learning_downloader,args=(s,))\n",
    "    t.start()\n",
    "    threadlist.append(t)\n",
    "    #sets top limit of active threads to 50\n",
    "    while threading.activeCount()>50:\n",
    "        a=0\n",
    "    #print threading.activeCount()\n",
    "\n",
    "for b in threadlist:\n",
    "    b.join()\n",
    "print (\"# of threads: \", len(threadlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-a2bc315fd502>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#Gradiant Boosting Ensemble learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'classification score: %s'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mclfP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1544\u001b[0m         n_stages = self._fit_stages(\n\u001b[0;32m   1545\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1546\u001b[1;33m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1608\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[0;32m   1609\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m   1242\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m-> 1244\u001b[1;33m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1158\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#load and combine downloaded data for initial learning\n",
    "ml_df = pd.DataFrame()\n",
    "directory = './data_s'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.p'):\n",
    "        stock_df = pd.read_pickle(os.path.join(directory, filename)) \n",
    "        if len(ml_df) == 0:\n",
    "            #using current bit of data for initial learning\n",
    "            ml_df = stock_df\n",
    "        else:\n",
    "            ml_df = ml_df.append(stock_df)\n",
    "            \n",
    "#not making decision on intraday close high low and volumes\n",
    "ml_df = ml_df.drop(['c_0'], axis=1)\n",
    "#regression learning data prep\n",
    "Xr = np.array(ml_df.drop(['r'],1))\n",
    "yr = np.array(ml_df['r'])\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr,yr,test_size= 0.2)\n",
    "\n",
    "#classification data prep\n",
    "ml_df['r'] = ml_df['r'].map(positive_negative)\n",
    "X = np.array(ml_df.drop(['r'],1))\n",
    "y = np.array(ml_df['r'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 0.2)\n",
    "\n",
    "#Gradiant Boosting Ensemble learning\n",
    "clf = GradientBoostingClassifier(learning_rate= 0.1, n_estimators= 100, max_depth= 5).fit(X_train,y_train)\n",
    "print ('classification score: %s'%(clf.score(X_test, y_test)))\n",
    "clfP = GradientBoostingClassifier (learning_rate= 0.1, n_estimators= 100, max_depth= 5).fit(X,y)\n",
    "with open('init_mplClassifier.p','wb') as f:\n",
    "    pk.dump(clfP,f)\n",
    "\n",
    "#GBE regression learning\n",
    "clfR = GradientBoostingRegressor(learning_rate= 0.01, n_estimators= 100, max_depth= 5).fit(Xr_train,yr_train)\n",
    "print ('regression score: %s'%(clfR.score(Xr_test, yr_test)))\n",
    "clfPR = GradientBoostingRegressor (learning_rate= 0.01, n_estimators= 100, max_depth= 5).fit(Xr,yr)\n",
    "with open('init_mplRegressor.p','wb') as f:\n",
    "    pk.dump(clfPR,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#partial fit\n",
    "clfP = pk.load(open('init_mplClassifier.p','rb'))\n",
    "clfPR = pk.load(open('init_mplRegressor.p','rb'))\n",
    "\n",
    "#adjusting hyper parameters for partial fit\n",
    "clfP.learning_rate='invscaling'\n",
    "clfP.warm_start = True\n",
    "clfP.learning_rate_init=0.0001\n",
    "clfP.max_iter=2000\n",
    "clfP.tol=1e-6\n",
    "clfP.momentum=0.7\n",
    "clfP.validation_fraction=0.2\n",
    "clfPR.learning_rate='invscaling'\n",
    "clfPR.warm_start = True\n",
    "clfPR.learning_rate_init=0.0001\n",
    "clfPR.max_iter=2000\n",
    "clfPR.tol=1e-6\n",
    "clfPR.momentum=0.7\n",
    "clfPR.validation_fraction=0.2\n",
    "\n",
    "directory = './data_s'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.p'):\n",
    "        stock_df = pk.load(open(os.path.join(directory, filename),'rb'))\n",
    "        stock_df = stock_df.drop(['c_0','v_0','h_0','l_0'], axis=1)\n",
    "        stock_df = stock_df.dropna()\n",
    "        stock_df = stock_df[~(stock_df == np.inf).any(axis=1)]\n",
    "        if len(stock_df) != 0:\n",
    "            try:\n",
    "                Xpr = np.array(stock_df.drop(['r'],1))\n",
    "                ypr = np.array(stock_df['r'])\n",
    "                Xpr, ypr = shuffle(Xpr,ypr,random_state=0)\n",
    "                clfPR.partial_fit(Xpr,ypr)\n",
    "                stock_df['r'] = stock_df['r'].map(positive_negative)\n",
    "                Xp = np.array(stock_df.drop(['r'],1))\n",
    "                yp = np.array(stock_df['r'])\n",
    "                Xp, yp = shuffle(Xp,yp,random_state=0)\n",
    "                clfP.partial_fit(Xp,yp, classes=np.array([0, 1]))\n",
    "            except:\n",
    "                pass\n",
    "with open('mlpClassifier.p','wb') as f:\n",
    "    pk.dump(clfP,f)\n",
    "with open('mlpRegressor.p','wb') as f:\n",
    "    pk.dump(clfPR,f)\n",
    "print 'classification score: %s'%(clfP.score(X_train, y_train))\n",
    "print 'regression score: %s'%(clfPR.score(Xr_train, yr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tndm will go [1] by [-0.01038422], prediction date: 20180406\n",
      "tndm will go [1] by [-0.01038422], prediction date: 20180406\n",
      "tndm will go [1] by [-0.01038422], prediction date: 20180406\n",
      "              close  high   low  open   volume         r\n",
      "tndm20180403   5.16  5.19  4.81  4.99  1677700  0.034068\n",
      "tndm20180404   5.41  5.47  5.01  5.12  2138600  0.056641\n",
      "tndm20180405   5.52  5.60  5.30  5.41  1752700  0.020333\n",
      "tndm20180406   5.75  5.88  5.40  5.40  2361714  0.064815\n"
     ]
    }
   ],
   "source": [
    "#prediction testing\n",
    "dt = datetime.datetime.now()\n",
    "UnixTime = int(time.mktime(dt.timetuple()))\n",
    "symbol = 'tndm'\n",
    "\n",
    "clf = pk.load(open('init_mplClassifier.p','rb'))\n",
    "clfR = pk.load(open('init_mplRegressor.p','rb'))\n",
    "for d in list(range(0,3))[::-1]:\n",
    "    print (stock_predict(symbol,clf,clfR,days_ago=d))\n",
    "\n",
    "#web variables\n",
    "url = 'https://query1.finance.yahoo.com/v8/finance/chart/'+symbol+'?period1='+str(UnixTime-86400*5)+'&period2='+str(UnixTime)+'&interval=1d&indicators=quote%7Csma~50&includePrePost=true&events=div%7Csplit%7Cearn&lang=en-CA&region=CA&corsDomain=ca.finance.yahoo.com'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.101 Safari/537.36',\n",
    "'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "'Connection': 'keep-alive'}\n",
    "#html data request\n",
    "request = urllib2.Request(url,headers = hdr)\n",
    "htmltext = urllib2.urlopen(request)\n",
    "\n",
    "data = json.load(htmltext)\n",
    "#json unpack\n",
    "timestamp = data['chart']['result'][0]['timestamp']\n",
    "timestamp = [datetime.datetime.fromtimestamp(x).strftime('%Y%m%d') for x in timestamp]\n",
    "quote = data['chart']['result'][0]['indicators']['quote'][0]\n",
    "stock_df = pd.DataFrame(quote)\n",
    "#index is symbol and timestamp\n",
    "stock_df.index = [symbol + str(x) for x in timestamp]\n",
    "stock_df = stock_df.dropna()\n",
    "stock_df['r'] = (stock_df['close']-stock_df['open'])/stock_df['open']\n",
    "print stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
